# scrapy_parser_pep

Проект асинхронного парсинга документации Python
Основная цель проекта
Изучение возможностей фреймворка Scrapy.

Описание проекта
Выполняется парсинг данных со страницы с общей информацией о PEP (https://peps.python.org/), переход по ссылкам и сбор данных о каждом PEP. Парсер подготавливает данные и сохраняет их в два файла формата csv в папку results.

Запуск проекта

Клонировать проект из репозитория
```git@github.com:vikolga/scrapy_parser_pep.git```

Создать, активировать виртуальное окружение и в него установить зависимости:

```python -m venv .env```

```source .env/Scripts/activate```

```pip install -r requirements.txt```

Запустить парсер из командной строки:

```scrapy crawl pep```

Результатом работы парсера будет создание двух файлов:

```pep_ДатаВремя.csv``` - содержит список всех PEP (number, name, status);

```status_summary_ДатаВремя.csv``` - содержит сводку по статусам PEP: сколько найдено документов в каждом статусе (Status, Quantity). В последней строке этого файла в колонке Total выводится общее количество всех документов.


Автор: Викторова Ольга